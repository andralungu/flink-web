<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title>Apache Flink: Introducing Flink Gelly</title>
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">

    <!-- Bootstrap -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/css/bootstrap.min.css">
    <link rel="stylesheet" href="/css/flink.css">
    <link rel="stylesheet" href="/css/syntax.css">

    <!-- Blog RSS feed -->
    <link href="/blog/feed.xml" rel="alternate" type="application/rss+xml" title="Apache Flink Blog: RSS feed" />

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
</head>
<body>


<!-- Top navbar. -->
<nav class="navbar navbar-default navbar-fixed-top">
    <div class="container">
        <!-- The logo. -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <div class="navbar-logo">
                <a href="/"><img alt="Apache Flink" src="/img/navbar-brand-logo.jpg" width="78px" height="40px"></a>
            </div>
        </div><!-- /.navbar-header -->

        <!-- The navigation links. -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav">
                <!-- Overview -->
                <li><a href="/index.html">Overview</a></li>

                <!-- Quickstart -->
                <li class="dropdown">
                    <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Quickstart <span class="caret"></span></a>
                    <ul class="dropdown-menu" role="menu">
                        <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-0.9/quickstart/setup_quickstart.html">Setup</a></li>
                        <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-0.9/quickstart/java_api_quickstart.html">Java API</a></li>
                        <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-0.9/quickstart/scala_api_quickstart.html">Scala API</a></li>
                        <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-0.9/quickstart/run_example_quickstart.html">Run Step-by-Step Example</a></li>
                    </ul>
                </li>

                <!-- Features -->
                <li><a href="/features.html">Features</a></li>

                <!-- Downloads -->
                <li><a href="/downloads.html">Downloads</a></li>

                <!-- Documentation -->
                <li class="dropdown">
                    <a href="" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Documentation <span class="caret"></span></a>
                    <ul class="dropdown-menu" role="menu">
                        <!-- Latest stable release -->
                        <li role="presentation" class="dropdown-header"><strong>Latest Release</strong> (Stable)</li>
                        <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-0.9">0.9.0 Documentation</a></li>
                        <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-0.9/api/java" class="active">0.9.0 Javadocs</a></li>
                        <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-0.9/api/scala/index.html" class="active">0.9.0 ScalaDocs</a></li>

                        <!-- Snapshot docs -->
                        <li class="divider"></li>
                        <li role="presentation" class="dropdown-header"><strong>Snapshot</strong> (Development)</li>
                        <li><a href="http://ci.apache.org/projects/flink/flink-docs-master">0.10 Documentation</a></li>
                        <li><a href="http://ci.apache.org/projects/flink/flink-docs-master/api/java" class="active">0.10 Javadocs</a></li>
                        <li><a href="http://ci.apache.org/projects/flink/flink-docs-master/api/scala/index.html" class="active">0.10 ScalaDocs</a></li>

                        <!-- Wiki -->
                        <li class="divider"></li>
                        <li><a href="https://cwiki.apache.org/confluence/display/FLINK/Apache+Flink+Home"><small><span class="glyphicon glyphicon-new-window"></span></small> Wiki</a></li>
                    </ul>
                </li>

                <!-- FAQ -->
                <li><a href="/faq.html">FAQ</a></li>
            </ul>

            <ul class="nav navbar-nav navbar-right">
                <!-- Blog -->
                <li class=" active hidden-md hidden-sm"><a href="/blog/">Blog</a></li>

                <li class="dropdown hidden-md hidden-sm">
                    <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Community <span class="caret"></span></a>
                    <ul class="dropdown-menu" role="menu">
                        <!-- Community -->
                        <li role="presentation" class="dropdown-header"><strong>Community</strong></li>
                        <li><a href="/community.html#mailing-lists">Mailing Lists</a></li>
                        <li><a href="/community.html#irc">IRC</a></li>
                        <li><a href="/community.html#stack-overflow">Stack Overflow</a></li>
                        <li><a href="/community.html#issue-tracker">Issue Tracker</a></li>
                        <li><a href="/community.html#source-code">Source Code</a></li>
                        <li><a href="/community.html#people">People</a></li>

                        <!-- Contribute -->
                        <li class="divider"></li>
                        <li role="presentation" class="dropdown-header"><strong>Contribute</strong></li>
                        <li><a href="/how-to-contribute.html">How to Contribute</a></li>
                        <li><a href="/coding-guidelines.html">Coding Guidelines</a></li>
                    </ul>
                </li>

                <li class="dropdown hidden-md hidden-sm">
                    <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Project <span class="caret"></span></a>
                    <ul class="dropdown-menu" role="menu">
                        <!-- Project -->
                        <li role="presentation" class="dropdown-header"><strong>Project</strong></li>
                        <li><a href="/material.html">Material</a></li>
                        <li><a href="https://twitter.com/apacheflink"><small><span class="glyphicon glyphicon-new-window"></span></small> Twitter</a></li>
                        <li><a href="https://github.com/apache/flink"><small><span class="glyphicon glyphicon-new-window"></span></small> GitHub</a></li>
                        <li><a href="https://cwiki.apache.org/confluence/display/FLINK/Apache+Flink+Home"><small><span class="glyphicon glyphicon-new-window"></span></small> Wiki</a></li>
                    </ul>
                </li>
            </ul>
        </div><!-- /.navbar-collapse -->
    </div><!-- /.container -->
</nav>


<!-- Main content. -->
<div class="container">

    <div class="row">
        <div class="col-sm-8 col-sm-offset-2">
            <div class="row">
                <h1>Introducing Flink Gelly</h1>

                <article>
                    <p>24 August 2015</p>

                    <p> This blog post introduces Gelly, Flink’s graph-processing API. Due to its native iteration
                        support, among other features, Apache Flink is a suitable platform for large-scale graph analytics.
                        By leveraging delta iterations, Gelly is able to map various graph processing models, such as
                        vertex-centric or gather-sum-apply, to Flink dataflows. </p>

                    <p>  Gelly allows Flink users to perform end-to-end data analysis, without having to build complex
                        pipelines and combine different systems. Gelly can be seamlessly used with Flink's DataSet API,
                        which means that pre-processing, graph creation, graph analysis and post-processing can be done
                        in the same application. At the end of this post, we will go through a step-by-step example,
                        in order to demonstrate that loading, transformation, filtering, graph creation and analysis,
                        can be performed with a single Flink program. </p>


                    <p><a href="#top"></a></p>

                    <p><a href="#top">Back to top</a></p>

                    <h2 id="what-is-gelly">What is Gelly?</h2>

                    <p> Gelly is a Graph API for Flink. It is currently supported in both Java and Scala.
                        The Scala methods are implemented as wrappers on top of the basic Java operations.
                        The API contains a set of utility functions for graph analysis, supports iterative graph
                        processing and introduces a library of graph algorithms.
                    </p>

                    <center>
                        <img src="/img/blog/flink-stack.png" style="width:90%;margin:15px" />
                    </center>

                    <p><a href="#top">Back to top</a></p>

                    <h2 id="graph-representation-and-creation">Graph Representation and Creation</h2>

                    <p> In Gelly, a graph is represented by a DataSet of vertices and a DataSet of edges.
                        A vertex is defined by its unique ID and a value, whereas an edge is defined by its source ID,
                        target ID and value. A vertex or edge for which a value is not specified will simply have the
                        value type set to NullValue. </p>

                    <p> A graph can, therefore, be created from:</p>
                    <ol>
                        <li>a DataSet of edges and an optional DataSet of vertices using <code>Graph.fromDataSet()</code></li>
                        <li>a DataSet of Tuple3 and an optional DataSet of Tuple2  using <code>Graph.fromTupleDataSet()</code></li>
                        <li>a Collection of edges and an optional Collection of vertices using <code>Graph.fromCollection()</code></li>
                    </ol>

                    <p> In all three cases, if the vertices are not provided,
                        Gelly will automatically produce the vertex IDs from the edge source and target IDs.</p>

                    <p><a href="#top">Back to top</a></p>

                    <h2 id="transformations-and-utilities">Transformations and Utilities</h2>

                    <p> These are methods of the Graph class and include common graph metrics, transformations
                        and mutations as well as neighborhood aggregations.</p>

                    <h4 id="common-graph-metrics">Common Graph Metrics</h4>

                    <p> These methods can be used to retrieve several graph metrics and properties, such as the number
                        of vertices, edges and the node degrees. </p>

                    <h4 id="tramsformations">Transformations</h4>

                    <p> The transformation methods enable several Graph operations, using high-level functions similar to
                        the ones provided by the batch processing API. These transformations can be applied one after the
                        other, yielding a new Graph after each step, in a fashion similar to operators on DataSets: </p>

                    <p><code> inputGraph.getUndirected().mapEdges(new CustomEdgeMapper()); </code></p>

                    <p> Transformations can be applied:</p>
                    <ol>
                        <li> on vertices: <code>mapVertices</code>, <code>joinWithVertices</code>, <code>filterOnVertices</code>, <code>addVertex</code>, ...</li>
                        <li> on edges: <code>mapEdges</code>, <code>filterOnEdges</code>, <code>removeEdge</code>, … </li>
                        <li> on triplets (source vertex, target vertex, edge): <code>getTriplets</code></li>
                    </ol>

                    <h4 id="neighborhood-aggregations">Neighborhood Aggregations</h4>

                    <p> Neighborhood methods allow vertices to perform an aggregation on their first-hop neighborhood.
                        This provides a vertex-centric view, where each vertex can access its neighboring edges and neighbor values.</p>

                    <p> <code>reduceOnEdges()</code> provides access to the neighboring edges of a vertex,
                        i.e. the edge value and the vertex ID of the edge endpoint. In order to also access the
                        neighboring vertices’ values, one should call the <code>reduceOnNeighbors()</code> function.
                        The scope of the neighborhood is defined by the EdgeDirection parameter, which can be IN, OUT or ALL,
                        to gather in-coming, out-going or all edges (neighbors) of a vertex. The two neighborhood
                        functions mentioned above can only be used when the aggregation function is associative and commutative.
                        In case the function does not comply with these restrictions or if it is desirable to return zero,
                        one or more values per vertex, the more general  <code>groupReduceOnEdges()</code> and
                        <code>groupReduceOnNeighbors()</code> functions must be called.</p>

                    <p> Consider, the following graph, for instance. </p>

                    <center>
                        <img src="/img/blog/neighborhood.png" style="width:90%;margin:15px" />
                    </center>

                    <p> Assume you would want to compute the sum of the values of all incoming neighbors, for each vertex.
                        Since the sum is an associative and commutative operation and since the neighbors’ values are needed,
                        we will call the <code>reduceOnNeighbors()</code> aggregation method: </p>

                    <p><code>graph.reduceOnNeighbors(new SumValues(), EdgeDirection.IN);</code></p>

                    <p> The vertex with id 1 is the only node that has no incoming edges. The result is therefore:</p>

                    <center>
                        <img src="/img/blog/reduce-on-neighbors.png" style="width:90%;margin:15px" />
                    </center>

                    <p><a href="#top">Back to top</a></p>

                    <h2 id="iterative-graph-processing">Iterative Graph Processing</h2>

                    <p> During the past few years, many different programming models for distributed graph processing
                        have been introduced: <a href="http://delivery.acm.org/10.1145/2490000/2484843/a22-salihoglu.pdf?ip=141.23.53.206&id=2484843&acc=ACTIVE%20SERVICE&key=2BA2C432AB83DA15.0F42380CB8DD3307.4D4702B0C3E38B35.4D4702B0C3E38B35&CFID=706313474&CFTOKEN=60107876&__acm__=1440408958_b131e035942130653e5782409b5c0cde">
                        vertex-centric</a>, <a href="http://researcher.ibm.com/researcher/files/us-ytian/giraph++.pdf">partition-centric</a>,
                        <a href="http://www.eecs.harvard.edu/cs261/notes/gonzalez-2012.htm">gather-apply-scatter</a>,
                        <a href="http://infoscience.epfl.ch/record/188535/files/paper.pdf">edge-centric</a>,
                        <a href="http://www.vldb.org/pvldb/vol7/p1673-quamar.pdf">neighborhood-centric</a>.
                        Each one of these models targets a specific class of graph applications and each corresponding
                        system implementation optimizes the runtime respectively. In Gelly, we would like to exploit the
                        flexible dataflow model and the efficient iterations of Flink, to support multiple distributed
                        graph processing models on top of the same system. </p>

                    <p> Currently, Gelly has methods for writing vertex-centric programs and provides support for programs
                        implemented using the gather-sum(accumulate)-apply model. We are also considering to offer support
                        for the partition-centric computation model, using Fink’s <code>mapPartition()</code> operator.
                        This model exposes the partition structure to the user and allows local graph structure exploitation
                        inside a partition to avoid unnecessary communication. </p>

                    <h4 id="vertex-centric">Vertex-centric</h4>

                    <p> Gelly wraps Flink’s <a href="https://ci.apache.org/projects/flink/flink-docs-release-0.8/spargel_guide.html">Spargel API</a> to support the vertex-centric, Pregel-like programming model.
                        Gelly’s runVertexCentricIteration method accepts two user-defined functions: </p>

                    <ol>
                        <li><strong>MessagingFunction:</strong> defines what messages a vertex sends out for the next superstep.</li>
                        <li><strong>VertexUpdateFunction:</strong> defines how a vertex will update its value based on the received messages.</li>
                    </ol>

                    <p> The method will execute the vertex-centric iteration on the input Graph and return a new Graph,
                        with updated vertex values. </p>

                    <p> Gelly’s vertex-centric programming model exploits Flink’s efficient delta iteration operators.
                        Many iterative graph algorithms expose non-uniform behavior, where some vertices converge to
                        their final value faster than others. In such cases, the number of vertices that need to be
                        recomputed during an iteration decreases as the algorithm moves towards convergence. </p>

                    <p> For example, consider a Single Source Shortest Paths problem on the following graph, where S
                        is the source node, i is the iteration counter and the edge values represent distances between nodes: </p>

                    <center>
                        <img src="/img/blog/sssp.png" style="width:90%;margin:15px" />
                    </center>

                    <p> In each iteration, a vertex receives distances from its neighbors and adopts the minimum of
                        these distances and its current distance as the new value. Then, it  propagates its new value
                        to its neighbors. If a vertex does not change value during an iteration, there is no need for
                        it to propagate its old distance to its neighbors; as they have already taken it into account. </p>

                    <p> Flink’s <em>IterateDelta</em> operator permits exploitation of this property as well as the
                        execution of computations solely on the active parts of the graph. The operator receives two
                        inputs: </p>

                    <ol>
                        <li> the <strong> Solution Set </strong>, which represents the current state of the input and</li>
                        <li> the <strong> Workset </strong>, which determines which parts of the graph will be recomputed in the next iteration.  </li>
                    </ol>

                    <p> In the SSSP example above, the Workset contains the vertices which update their distances.
                        The user-defined iterative function is applied on these inputs to produce state updates.
                        These updates are efficiently applied on the state, which is kept in memory. </p>

                    <center>
                        <img src="/img/blog/iteration.png" style="width:90%;margin:15px" />
                    </center>

                    <p> Internally, a vertex-centric iteration is a Flink delta iteration, where the initial Solution Set
                        is the vertex set of the input graph and the Workset is created by selecting the active vertices,
                        i.e. the ones that updated their value in the previous iteration. The messaging and vertex-update
                        functions are user-defined functions wrapped inside coGroup operators. In each superstep,
                        the active vertices (Workset) are coGrouped with the edges to generate the neighborhoods for
                        each vertex. The messaging function is then applied on each neighborhood. Next, the result of the
                        messaging function is coGrouped with the current vertex values (Solution Set) and the user-defined
                        vertex-update function is applied on the result. The output of this coGroup operator is finally
                        used to update the Solution Set and create the Workset input for the next iteration. </p>

                    <center>
                        <img src="/img/blog/vertex-centric-plan.png" style="width:90%;margin:15px" />
                    </center>

                    <h4 id="gather-sum-apply">Gather-Sum-Apply</h4>

                    <p> Gelly supports a variation of the popular Gather-Sum-Apply-Scatter  computation model,
                        introduced by PowerGraph. In GSA, a vertex pulls information from its neighbors as opposed to the
                        vertex-centric approach where the updates are pushed from the incoming neighbors.
                        The runGatherSumApplyIteration() accepts three user-defined functions: </p>

                    <ol>
                        <li><strong>GatherFunction:</strong> gathers neighboring partial values along in-edges. </li>
                        <li><strong>SumFunction:</strong> accumulates/reduces the values into a single one. </li>
                        <li><strong>ApplyFunction:</strong> uses the result computed in the sum phase to update the current vertex’s value. </li>
                    </ol>

                    <p> Similarly to vertex-centric, GSA leverages Flink’s delta iteration operators as, in many cases,
                        vertex values do not need to be recomputed during an iteration.</p>

                    <p> Let us reconsider the Single Source Shortest Paths algorithm. In each iteration, a vertex: </p>

                    <ol>
                        <li><strong>[Gather]</strong> retrieves distances from its neighbors summed up with the
                            corresponding edge values; </li>
                        <li><strong>[Sum]</strong> compares the newly obtained distances in order to extract the minimum;</li>
                        <li><strong>[Apply]</strong> and finally adopts the minimum distance computed in the sum step,
                            provided that it is lower than its current value. If a vertex’s value does not change during
                            an iteration, it no longer propagates its distance.</li>
                    </ol>

                    <p> Internally, a Gather-Sum-Apply Iteration is a Flink delta iteration where the initial solution
                        set is the vertex input set and the workset is created by selecting the active vertices. </p>

                    <p> The three functions: gather, sum and apply are user-defined functions wrapped in map, reduce
                        and join operators respectively. In each superstep, the active vertices are joined with the
                        edges in order to create neighborhoods for each vertex. The gather function is then applied on
                        the neighborhood values via a map function. Afterwards, the result is grouped by the vertex ID
                        and reduced using the sum function. Finally, the outcome of the sum phase is joined with the
                        current vertex values (solution set), the values are updated, thus creating a new workset that
                        serves as input for the next iteration. </p>

                    <center>
                        <img src="/img/blog/GSA-plan.png" style="width:90%;margin:15px" />
                    </center>

                    <p><a href="#top">Back to top</a></p>

                    <h2 id="library-of-graph-algorithms">Library of Graph Algorithms</h2>

                    <p> We are building a library of graph algorithms in Gelly, to easily analyze large-scale graphs.
                        These algorithms extend the <em>GraphAlgorithm</em> interface and can be simply executed on
                        the input graph by calling a <code>run()</code> method.</p>

                    <p>We currently have implementations of the following algorithms:</p>

                    <ul>
                        <li>PageRank</li>
                        <li>Single-Source-Shortest-Paths</li>
                        <li>Label Propagation</li>
                        <li>Community Detection (based on <a href="http://arxiv.org/pdf/0808.2633.pdf">this paper</a>)</li>
                        <li>Connected Components</li>
                        <li>GSA Connected Components</li>
                        <li>GSA PageRank</li>
                        <li>GSA Single-Source-Shortest-Paths</li>
                    </ul>

                    <p> Gelly also offers implementations of common graph algorithms through <a href="https://github.com/apache/flink/tree/master/flink-staging/flink-gelly/src/main/java/org/apache/flink/graph/example">examples</a>.
                        Among them, one can find graph weighting schemes, like Jaccard Similarity and Euclidean Distance
                        Weighting, as well as computation of common graph metrics.</p>

                    <p><a href="#top">Back to top</a></p>

                    <h2 id="use-case">Use-Case: Music Profiles</h2>

                    <p> In the following section, we go through a use-case scenario that combines the Flink DataSet API
                        with Gelly in order to process users’ music preferences to suggest additions to their playlist.</p>

                    <p> First, we read a user’s music profile which is in the form of user-id, song-id and the number of
                        plays that each song has. We then filter out the list of songs the users do not wish to see in their
                        playlist. Then we compute the top songs per user (i.e. the songs a user listened to the most).
                        Finally, as a separate use-case on the same data set, we create a user-user similarity graph based
                        on the common songs and use this resulting graph to detect communities by calling Gelly’s Label Propagation
                        library method. </p>

                    <p> For running the example implementation, please use the 0.10-SNAPSHOT version of Flink as a
                        dependency. The full example code base can be found <a href="https://github.com/apache/flink/blob/master/flink-staging/flink-gelly/src/main/java/org/apache/flink/graph/example/MusicProfiles.java">here</a>; The public data set used for testing
                        can be found <a href="http://labrosa.ee.columbia.edu/millionsong/tasteprofile">here</a>. This data set contains <strong>48,373,586</strong> real user-id, song-id and
                        play-count triplets.</p>

                    <h4 id="filtering-out-bad-records">Filtering out Bad Records</h4>

                    <p> After reading the (user-id, song-id, play-count) triplets from a CSV file and after parsing a
                        text file in order to retrieve the list of songs that a user would not want to include in a
                        playlist, we use a coGroup function to filter out the mismatches.  </p>

                    <div class="highlight"><pre><code class="language-java">
                        // read the user-song-play triplets.
                        DataSet&ltTuple3&ltString, String, Integer&gt&gt triplets =
                                                                getUserSongTripletsData(env);

                        // read the mismatches dataset and extract the songIDs
                        DataSet&ltTuple3&ltString, String, Integer&gt&gt validTriplets = triplets
                                .coGroup(mismatches).where(1).equalTo(0)
                                .with(new CoGroupFunction {
                                    void coGroup(Iterable triplets, Iterable invalidSongs, Collector out) {
                                        if (!invalidSongs.iterator().hasNext())
                                            for (Tuple3 triplet : triplets) // valid triplet
                                                out.collect(triplet);
                                    }
                                }

                    </code></pre></div>

                    <p>The coGroup simply takes the triplets whose song-id (second field) matches the song-id from the
                        mismatches list (first field) and if the iterator was empty for a certain triplet, meaning that
                        there were no mismatches found, the triplet associated with that song is collected. </p>

                    <h4 id="compute-the-top-songs-per-user">Compute the Top Songs per User</h4>

                    <p> As a next step, we would like to see which songs a user played more often. To this end, we
                        build a user-song weighted, bipartite graph in which edge source vertices are users, edge target
                        vertices are songs and where the weight represents the number of times the user listened to that
                        certain song. </p>

                    <center>
                        <img src="/img/blog/user-song-graph.png" style="width:90%;margin:15px" />
                    </center>

                    <div class="highlight"><pre><code class="language-java">
                        // create a user -> song weighted bipartite graph where the edge weights
                        // correspond to play counts
                        Graph&ltString, NullValue, Integer&gt userSongGraph = Graph.fromTupleDataSet(validTriplets, env);
                    </code></pre></div>

                    <p> Consult the <a href="https://ci.apache.org/projects/flink/flink-docs-master/libs/gelly_guide.html">Gelly guide</a> for guidelines on how to create a graph from a given DataSet of edges
                        or from a collection.</p>

                    <p> To retrieve the top songs per user, we call the groupReduceOnEdges function as it perform an
                        aggregation over the first hop neighborhood taking just the edges into consideration. We will
                        basically iterate through the edge value and collect the target (song) of the maximum weight edge.</p>

                    <div class="highlight"><pre><code class="language-java">
                        //get the top track (most listened to) for each user
                        DataSet&ltTuple2&gt usersWithTopTrack = userSongGraph
                                        .groupReduceOnEdges(new GetTopSongPerUser(), EdgeDirection.OUT);

                        class GetTopSongPerUser implements EdgesFunctionWithVertexValue {
                            void iterateEdges(Vertex vertex, Iterable&ltEdge&gt edges) {
                                int maxPlaycount = 0;
                                String topSong = "";

                                for (Edge edge : edges) {
                                    if (edge.getValue() > maxPlaycount) {
                                        maxPlaycount = edge.getValue();
                                        topSong = edge.getTarget();
                                    }
                                }
                                return new Tuple2(vertex.getId(), topSong);
                            }
                        }
                    </code></pre></div>

                    <h4 id="creating-a-user-user-similarity-graph">Creating a user-user Similarity Graph</h4>

                    <p> Clustering users based on common interests, in this case, common top songs, could prove to be
                        very useful for advertisements or for recommending new musical compilations. In a user-user graph,
                        two users who listen to the same song will simply be linked together through an edge as depicted
                        in the figure below. </p>

                    <center>
                        <img src="/img/blog/user-song-to-user-user.png" style="width:90%;margin:15px" />
                    </center>

                    <p> To form the user-user graph in Flink, we will simply take the edges from the user-song graph
                        (left-hand side of the image), group them by song-id, and then add all the users (source vertex ids)
                        to an ArrayList.  </p>

                    <p> We then match users who listened to the same song two by two, creating a new edge to mark their
                        common interest (right-hand side of the image).  </p>

                    <p> Afterwards, we perform a <code>distinct()</code> operation to avoid creation of duplicate data.
                        Considering that we now have the DataSet of edges which present interest, creating a graph is as
                        straightforward as a call to the <code>Graph.fromDataSet()</code> method. </p>

                    <div class="highlight"><pre><code class="language-java">
                        // create a user-user similarity graph:
                        // two users that listen to the same song are connected
                        DataSet&ltEdge&gt similarUsers = userSongGraph.getEdges()
                                // filter out user-song edges that are below the playcount threshold
                                .filter(new FilterFunction&ltEdge&ltString, Integer&gt&gt() {
                                    public boolean filter(Edge&ltString, Integer&gt edge) {
                                        return (edge.getValue() > playcountThreshold);
                                    }
                                }).groupBy(1)
                                .reduceGroup(new GroupReduceFunction() {
                                    void reduce(Iterable&ltEdge&gt edges, Collector&ltEdge&gt out) {
                                        List users = new ArrayList();
                                        for (Edge edge : edges)
                                            users.add(edge.getSource());
                                            for (int i = 0; i < users.size() - 1; i++)
                                                for (int j = i+1; j < users.size() - 1; j++)
                                                    out.collect(new Edge(users.get(i), users.get(j)));
                                    }
                                }).distinct();

                        Graph similarUsersGraph = Graph.fromDataSet(similarUsers).getUndirected();
                    </code></pre></div>

                    <h4 id="detecting-communities">Detecting Communities</h4>

                    <p> After having created a user-user graph, it would make sense to detect the various communities
                        formed. To do so, we first initialize each vertex with a numeric label using the
                        <code>joinWithVertices()</code> function that takes a data set of Tuple2 as a parameter and joins
                        the id of a vertex with the first element of the tuple, afterwards applying a map function.
                        Finally, we call the <code>run()</code> method with the LabelPropagation library method passed
                        as a parameter. In the end, the vertices will be updated to contain the most frequent label
                        among their neighbors. </p>

                    <div class="highlight"><pre><code class="language-java">
                        // detect user communities using label propagation
                        // initialize each vertex with a unique numeric label
                        DataSet&ltTuple2&ltString, Long&gt&gt idsWithInitialLabels = DataSetUtils
                                .zipWithUniqueId(similarUsersGraph.getVertexIds())
                                .map(new MapFunction&ltTuple2&ltLong, String&gt, Tuple2&ltString, Long&gt&gt() {
                                    @Override
                                    public Tuple2&ltString, Long&gt map(Tuple2&ltLong, String&gt tuple2) throws Exception {
                                        return new Tuple2&ltString, Long&gt(tuple2.f1, tuple2.f0);
                                    }
                                });

                        // update the vertex values and run the label propagation algorithm
                        DataSet&ltVertex&gt verticesWithCommunity = similarUsersGraph
                            .joinWithVertices(idsWithlLabels, new MapFunction() {
                                public Long map(Tuple2 idWithLabel) {
                                    return idWithLabel.f1;
                                }
                            }).run(new LabelPropagation(numIterations)).getVertices();

                    </code></pre></div>

                    <p><a href="#top">Back to top</a></p>

                    <h2 id="ongoing-and-future-work">Ongoing and Future Work</h2>

                    <p> Currently, Gelly matches the basic functionalities provided by most state-of-the-art graph
                        processing systems. Our vision is to turn Gelly into more than “yet another library for running
                        PageRank-like algorithms” by supporting generic iterations, implementing graph partitioning,
                        providing bipartite graph support and by offering numerous other features.  </p>

                    <p> We are also enriching Flink Gelly with a set of operators suitable for highly skewed graphs
                        as well as a Graph API built on Flink Streaming. </p>

                    <p> In the near future, we would like to see how Gelly can be integrated with graph visualization
                        tools, graph database systems and sampling techniques. </p>

                    <p> Curious? Read more about our plans for Gelly in the <a  href="https://cwiki.apache.org/confluence/display/FLINK/Flink+Gelly">roadmap</a>.</p>

                    <p><a href="#top">Back to top</a></p>

                    <h2 id="links">Links</h2>

                    <p> <a href="https://ci.apache.org/projects/flink/flink-docs-master/libs/gelly_guide.html"> Gelly Documentation </a> </p>
                </article>
            </div>

    <div class="row">
    <div id="disqus_thread"></div>
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'stratosphere-eu'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
</div>
</div>
</div>

<hr />
<div class="footer text-center">
    <p>Copyright © 2014-2015 <a href="http://apache.org">The Apache Software Foundation</a>. All Rights Reserved.</p>
    <p>Apache Flink, Apache, and the Apache feather logo are trademarks of The Apache Software Foundation.</p>
    <p><a href="/privacy-policy.html">Privacy Policy</a> &middot; <a href="/blog/feed.xml">RSS feed</a></p>
</div>

</div><!-- /.container -->

<!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.2/jquery.min.js"></script>
<!-- Include all compiled plugins (below), or include individual files as needed -->
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
<script src="/js/codetabs.js"></script>

<!-- Google Analytics -->
<script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
                (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-52545728-1', 'auto');
    ga('send', 'pageview');
</script>
</body>
</html>
